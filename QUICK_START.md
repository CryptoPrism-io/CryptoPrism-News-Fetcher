# üöÄ Quick Start Guide - Hourly News Fetcher

## ‚úÖ System Ready!

Your automated hourly crypto news fetching system is **fully implemented and tested**. Here's everything you need to get it running.

---

## üìä What's Running Right Now

‚úÖ **Database:** PostgreSQL table `cc_news` created with **65 articles**
‚úÖ **Latest exports:** CSV, JSON, and analysis files ready
‚úÖ **GitHub Actions:** Workflow file created (needs secrets to activate)

---

## üéØ Next Steps (5 minutes)

### Step 1: Add GitHub Secrets

Go to your GitHub repository:
1. **Settings** ‚Üí **Secrets and variables** ‚Üí **Actions**
2. Click **"New repository secret"**
3. Add these 6 secrets:

| Secret Name | Value (from your .env) |
|-------------|------------------------|
| `CRYPTOCOMPARE_API_KEY` | `(your API key)` |
| `DB_HOST` | `34.55.195.199` |
| `DB_PORT` | `5432` |
| `DB_USER` | `yogass09` |
| `DB_PASSWORD` | `jaimaakamakhya` |
| `DB_NAME` | `dbcp` |

### Step 2: Enable GitHub Actions

1. Go to **Actions** tab in your repo
2. Enable workflows if asked
3. You'll see: **"Hourly Crypto News Fetch"**
4. Click **"Run workflow"** to test manually

---

## üïê Automated Schedule

Once secrets are added, the workflow will:
- Run **every hour** at :00 minutes (1:00, 2:00, 3:00, etc.)
- Fetch articles from **last 1 hour**
- Store in **PostgreSQL** (`cc_news` table)
- Export latest **CSV/JSON**
- Clean up **old files**

---

## üíª Manual Testing (Local)

### Test Database Connection
```bash
python -m src.news_fetcher.db_cc_news
```

### Run Manual Fetch
```bash
python -m src.news_fetcher.fetch_hourly
```

### Check Latest Data
```bash
# View latest CSV
cat data/csv_exports/crypto_news_hourly_*.csv | head -20

# Check database stats
python -m src.news_fetcher.db_cc_news
```

---

## üóÑÔ∏è Query Your Data

### Connect to Database
```bash
psql -h 34.55.195.199 -U yogass09 -d dbcp
```

### Useful Queries
```sql
-- Latest 10 articles
SELECT title, published_on, source_name
FROM cc_news
ORDER BY published_on DESC
LIMIT 10;

-- Articles from last 24 hours
SELECT COUNT(*) FROM cc_news
WHERE published_on >= NOW() - INTERVAL '24 hours';

-- Top sources
SELECT source_name, COUNT(*)
FROM cc_news
GROUP BY source_name
ORDER BY COUNT(*) DESC;

-- Bitcoin articles
SELECT title, published_on
FROM cc_news
WHERE categories LIKE '%BTC%'
ORDER BY published_on DESC
LIMIT 10;
```

**More queries:** See [sql/query_examples.sql](sql/query_examples.sql)

---

## üìÅ File Locations

| File | Purpose |
|------|---------|
| `src/news_fetcher/fetch_hourly.py` | Main hourly fetcher |
| `src/news_fetcher/db_cc_news.py` | Database connector |
| `.github/workflows/hourly-news-fetch.yml` | GitHub Actions |
| `data/csv_exports/crypto_news_hourly_*.csv` | Latest CSV export |
| `data/json_exports/crypto_news_hourly_*.json` | Latest JSON export |
| `sql/query_examples.sql` | 50+ SQL queries |
| `HOURLY_FETCH_SETUP.md` | Detailed documentation |

---

## üìä What to Expect

### Per Hour
- **50-70 articles** fetched
- **15-25 sources**
- **~40-60 new** in database (rest are duplicates)
- **100% image** coverage
- **Full body text** stored

### Daily
- **~1,200-1,680 articles** total
- **20-30 unique sources**
- **CSV/JSON exports** updated every hour

---

## üîç Monitoring

### Check GitHub Actions
1. Go to **Actions** tab
2. Click latest "Hourly Crypto News Fetch" run
3. View logs to see:
   - Articles fetched
   - Database insertions
   - Cleanup operations

### Check Database Growth
```sql
-- Total articles
SELECT COUNT(*) FROM cc_news;

-- Articles per day
SELECT DATE(published_on), COUNT(*)
FROM cc_news
GROUP BY DATE(published_on)
ORDER BY DATE DESC;

-- Table size
SELECT pg_size_pretty(pg_total_relation_size('cc_news'));
```

---

## ‚ö†Ô∏è Troubleshooting

### GitHub Actions not running?
- Check secrets are added correctly
- Enable workflows in Actions tab
- Check cron schedule (runs at :00 of every hour)

### Database connection failed?
```bash
# Test locally
python -m src.news_fetcher.db_cc_news

# Check .env file has correct credentials
cat .env
```

### No new articles?
- Normal! Sometimes fewer than 50 articles in last hour
- Check API key is valid
- Duplicates are expected (overlapping time windows)

---

## üéâ Success Criteria

‚úÖ Articles fetch every hour automatically
‚úÖ Data stored in PostgreSQL
‚úÖ No duplicate URLs in database
‚úÖ Old exports cleaned up
‚úÖ Can query data via SQL
‚úÖ GitHub Actions workflow runs without errors

**All systems operational!** üöÄ

---

## üìö Full Documentation

- **Detailed Setup:** [HOURLY_FETCH_SETUP.md](HOURLY_FETCH_SETUP.md)
- **Implementation Notes:** [IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md)
- **SQL Queries:** [sql/query_examples.sql](sql/query_examples.sql)
- **Changelog:** [CHANGELOG.md](CHANGELOG.md)

---

## üÜò Quick Commands Cheat Sheet

```bash
# Run hourly fetch manually
python -m src.news_fetcher.fetch_hourly

# Check database stats
python -m src.news_fetcher.db_cc_news

# Connect to database
psql -h 34.55.195.199 -U yogass09 -d dbcp

# View latest CSV
head -20 data/csv_exports/crypto_news_hourly_*.csv

# Check git status
git status

# Push to GitHub
git push origin master
```

---

**Ready to go! Add GitHub secrets and you're live.** ‚úÖ

*Last updated: October 21, 2025*
